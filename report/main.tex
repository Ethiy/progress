\documentclass[a4paper, 11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{hyperref}

\usepackage{standalone}

\usepackage{rotating}

\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{floatrow}
\captionsetup{labelsep=period}

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}

\usepackage{array}
\newcolumntype{x}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\usepackage{tabulary}
\usepackage{booktabs}

\usepackage{enumerate}

\usepackage{amsmath}

\usepackage{fullpage}

\newcounter{SubFigCounter}
\setcounter{SubFigCounter}{1}

\begin{document}
	\begin{centering}
		\Large{\textbf{Progress Report}}\\
		\large{\today}
~\\
		Oussama ENNAFII\\
		Directors: Cl\'ement Mallet \& Florent Lafarge \\
		Advisor: Arnaud Le Bris \\

	\end{centering}


	\section{The Dataset}
~\\

	We dropped off \textit{Nantes} and \textit{Dijon} for the moment, as the \textit{3DS} scenes are not well formated. We will take care of these once we have a simple, not too time consuming, solution to read the \textit{cityGML} files. In consequence, We are focusing, right now, on \href{https://www.google.fr/maps/place/%C3%89lancourt/@48.7781732,1.9536264,5868m/data=!3m1!1e3!4m13!1m7!3m6!1s0x47e68370e965167b:0x705d83a4167c877c!2s%C3%89lancourt!3b1!8m2!3d48.782907!4d1.960077!3m4!1s0x47e68370e965167b:0x705d83a4167c877c!8m2!3d48.782907!4d1.960077}{\textit{Elancourt}}.\\

	We describe fully the dataset used for this study in the next subsection.

	\subsection{Description}
~\\

	We have around $3,78\text{ K}m^2$ of reconstructed area --- \textit{c.f.} Figure~\ref{fig::snaps}. The $3D$ buildings are obtained by an industrialized version of the \textit{Bati3D} method~\cite{durupt2006automatic, taillandier2004automatic}. In order to qualify the urban scene, we have also aquirred the corresponding \textit{DSM}s --- Figure~\ref{fig::errors_sample} --- and \textit{Orthoimages} --- Figure~\ref{fig::ortho}.

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\begin{minipage}[c]{\textwidth}
			\ffigbox[\FBwidth]
			{
				\begin{subfloatrow}[2]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.45\textwidth]{../images/raster/snapshot_1}}
					}
					{
						\caption{Snapshot of the 3D scene.}\label{fig::snap1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.45\textwidth]{../images/raster/snapshot_2}}
					}
					{
						\caption{Snapshot of the 3D scene.}\label{fig::snap2}
					}
				\end{subfloatrow}
			}
			{
				\caption{\label{fig::snaps} Snapshot of the annotated scene.}
			}
		\end{minipage}
	\end{figure}

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\ffigbox[\FBwidth]
		{
			\begin{subfloatrow}[3]
				\captionsetup{labelformat=brace, justification=raggedright}
				\ffigbox[\FBwidth]
				{
					\fbox{\includegraphics[width=.29\textwidth]{../images/raster/snapshot_1}}
				}
				{
					\caption{Snapshot of the 3D scene.}\label{fig::snapshot}
				}
				\ffigbox[\FBwidth]
				{
					\fbox{\includegraphics[width=.285\textwidth]{../images/raster/orthoimage}}
				}
				{
					\caption{Orthoimage corresponding to the scene.}\label{fig::ortho}
				}
				\ffigbox[\FBwidth]
				{
					\fbox{\includegraphics[width=.33\textwidth]{../images/raster/errors_sample}}
				}
				{
					\caption{Labelled errors sample.}\label{fig::errors_sample}
				}
			\end{subfloatrow}
		}
		{
			\caption{\label{fig::dataset} Labelled dataset.}
		}
	\end{figure}

	\subsection{Annotated errors}
~\\

	The taxonomy has evolved from the one proposed in earlier work~\cite{michelin2013quality}. The high level --- LoD based --- discrimination matured during the manual annotation into three metaclasses. Each one of these metaclasses is itself subdivided into errors. The errors are chosen to represent atomic flaws, in order to keep the taxonomy stable enough in case we expand to other regions. In fact, in case we stumble upon new cases we can feed each metaclass by corresponding erros. Multiple errors can alter a single building. The metaclasses are chosen to correlate to LoD levels: we estimate that this reprentation will not evolve further in the future.

	We proceed now to descibe, in full detail, these classes:

	\begin{enumerate}[(i)]
		\item Unqualified Building Errors (\textit{c.f.} Figure~\ref{fig::samples}\ref{fig::unq_bul}): buildings will not be taken into consideration, since we know before hand that they are not taken into account by the reconstruction method:
		\item Building Errors (\textit{c.f.} Figure~\ref{fig::samples}\ref{fig::bul_err}): encompasses the errors that affect the whole building (corrensponds roughly to $LoD0$ and $LoD1$ errors),
		\item Facet Errors (\textit{c.f.} Figure~\ref{fig::samples}\ref{fig::fac_err}): concerns errors affecting only a facet.
	\end{enumerate}

	The errors are summarized into a mindmap --- \textit{c.f.} Figure~\ref{fig::mindmap_errors}.

	\begin{sidewaysfigure}[p]
		\begin{center}
			\includestandalone[mode=buildnew, scale=.78]{mind_map}
			\caption{\label{fig::mindmap_errors} Mind map summarizing the errors encountered during annotation.}
		\end{center}
	\end{sidewaysfigure}

	In Table~\ref{tab::label_stats} we present some statistics over the labelled dataset (\textit{c.f.} Figure~\ref{fig::dataset}) comprizing $502$ buildings:

	\begin{sidewaystable}[H]
		\centering
		\caption{\label{tab::label_stats} Label statistics over the $502$ building dataset.}
		\begin{tabular}{x{4cm} | x{3cm} | x{3cm} | x{3cm} | x{3cm}}
			\toprule
			\multicolumn{1}{c|}{\textbf{Error Class}} & \textbf{Occurence probability} & \textbf{Subclass} & \textbf{Class conditionnal occurence probability} & \textbf{Absolute occurence probability} \\
			\midrule
			\multirow{4}{*}{Unqualified Buildings} & \multirow{4}{*}{$0.0876$} & Half Building & $0.8636$ & $0.0757$ \\
			\cline{3-5}
				&                   & Changed Building & $0.0455$ & $0.0040$ \\
			\cline{3-5}
				&                   & Occlusion & $0.0455$ & $0.0040$ \\
			\cline{3-5}
				&                   & Unknown & $0.0455$ & $0.0040$ \\
			\midrule
			\midrule
			\multirow{4}{*}{Building Error} & \multirow{4}{*}{$0.2408$} & Over Segmentation & $0.1365$ & $0.0328$\\
			\cline{3-5}
				&                   & Under Segmentation & $0.4177$ & $0.1006$ \\
			\cline{3-5}
				&                   & Footprint & $0.4839$ & $0.1165$ \\
			\cline{3-5}
				&                   & Altimetric & $0.0165$ & $0.0040$ \\
			\midrule
			\midrule
			\multirow{4}{*}{Facet Errors} & \multirow{4}{*}{$0.81657$} & Over Segmentation & $0.8830$ & $0.7203$ \\
			\cline{3-5}
				&                   & Under Segmentation & $0.0842$ & $0.0687$ \\
			\cline{3-5}
				&                   & Mis Segmentation & $0.0806$ & $0.0657$ \\
			\cline{3-5}
				&                   & Slope & $0.0327$ & $0.0267$ \\
			\bottomrule
		\end{tabular}
	\end{sidewaystable}

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\begin{center}
			\ffigbox{
				\ffigbox[\FBwidth]{
					\begin{subfloatrow}[4]
						\captionsetup{labelformat=brace, justification=raggedright}
						\ffigbox[\FBwidth]{\caption{Half Building: only a portion of the building is reconstructed.}\label{fig::half_building}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Unqualified_Errors/half_building}}}
						\ffigbox[\FBwidth]{\caption{Changed Building: the building has changed so we cannot qualify it.}\label{fig::changed}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Unqualified_Errors/changed}}}
						\ffigbox[\FBwidth]{\caption{Occlusion: the building is occluded by vegetation here.}\label{fig::occlusion}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Unqualified_Errors/occlusion}}}
						\ffigbox[\FBwidth]{\caption{Unknown: Unknown shape that cannot be verified on the ground.}\label{fig::unknown}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Unqualified_Errors/unknown}}}
					\end{subfloatrow}
				}
				{
					\renewcommand\figurename{}
					\renewcommand{\thefigure}{(\roman{SubFigCounter})}

					\caption{Unqualified building errors samples.}\label{fig::unq_bul}
					\refstepcounter{SubFigCounter}
				}
				\ffigbox[\FBwidth]
				{
					\begin{subfloatrow}[4]
						\captionsetup{labelformat=brace, justification=raggedright}
						\ffigbox[\FBwidth]{\caption{Under Segmentation: Two or more buildings grouped into one.}\label{fig::under_bul}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Building_Errors/under_segmentation}}}
						\ffigbox[\FBwidth]{\caption{Over segmentation: One building segmented into two or more buildings.}\label{fig::over_bul}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Building_Errors/over_segmentation}}}
						\ffigbox[\FBwidth]{\caption{Footprint: Wrong building footprint.}\label{fig::footprint}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Building_Errors/footprint}}}
						\ffigbox[\FBwidth]{\caption{Altitude: Wrong building height.}\label{fig::too_low}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Building_Errors/altimetric}}}
					\end{subfloatrow}
				}
				{
					\renewcommand\figurename{}
					\renewcommand{\thefigure}{(\roman{SubFigCounter})}

					\caption{Building errors samples.}\label{fig::bul_err}
					\refstepcounter{SubFigCounter}
				}
				\ffigbox[\FBwidth]
				{
					\begin{subfloatrow}[4]
						\captionsetup{labelformat=brace, justification=raggedright}
						\ffigbox[\FBwidth]{\caption{Under Segmentation: Two facets or more grouped into one.}\label{fig::under_fac}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Facet_Errors/under_segmentation}}}
						\ffigbox[\FBwidth]{\caption{Over segmentation: One facet segemented into two or more facets.}\label{fig::over_fac}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Facet_Errors/over_segmentation}}}
						\ffigbox[\FBwidth]{\caption{Mis Segmentation: Facet edges do not correspond to real ones.}\label{fig::mis}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Facet_Errors/mis_segmentation}}}
						\ffigbox[\FBwidth]{\caption{Slope: Wrong facet slope.}\label{fig::slope}}{\fbox{\includegraphics[width=.24\textwidth]{../images/raster/Facet_Errors/slope}}}
					\end{subfloatrow}
				}
				{
					\renewcommand\figurename{}
					\renewcommand{\thefigure}{(\roman{SubFigCounter})}

					\caption{Facet errors samples.}\label{fig::fac_err}
					\refstepcounter{SubFigCounter}
				}
			}
			{
				\addtocounter{figure}{-3}
				\caption{\label{fig::samples}Error taxonomy illustration.}
			}
		\end{center}
	\end{figure}

	\section{Features}
~\\

	\subsection{Low level features}


	The first step of computing features was to extract low level features and expose them so that I can engineer sophisticated features to train the classifiers on. In fact, For each building, I computed the facet adjacency graph --- \textit{c.f.} Figure~\ref{fig::geom_features} --- with meaningful information for each facet. I also computed the orthoprojection\footnote{Projection on the Plane $(O, \vec{\imath}, \vec{\jmath})$} of buildings and stored it in vectorial --- \textit{c.f.} Figure~\ref{fig::vector} --- and raster mode --- \textit{c.f.} Figure~\ref{fig::raster}.\\

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\ffigbox[\FBwidth]
		{
			\begin{subfloatrow}[2]
				\captionsetup{labelformat=brace, justification=raggedright}
				\ffigbox[\FBwidth]
				{\caption{Raster orthoprojection.}\label{fig::raster}}{\includegraphics[width=.48\textwidth]{../images/raster/raster_projection}}
				\ffigbox[\FBwidth]{\caption{Vector orthoprojections (in transparent blue).}\label{fig::vector}}{\includegraphics[width=.48\textwidth]{../images/raster/vector_projection}}
			\end{subfloatrow}
		}
		{
			\caption{\label{fig::orthoproj}Scene orthoprojections.}
		}
	\end{figure}

	\begin{figure}[H]
		\includestandalone[mode=buildnew, scale=1]{dual_features}
		\caption{\label{fig::geom_features} Low level geometric features per building.}
	\end{figure}
	\clearpage

	\subsection{Mid level features}
~\\

	The previous features are raw and not useful for classification. As a first
	step, in order to establish a baseline for the qualification, I choose simple
	features that can be classed as follows:
	\begin{itemize}
		\item[(i).] Geometric --- or intrinsic --- features: based on the graph adjacency features and the vector orthoprojections, I tried the feature vector per building in equation~\ref{eq::feature_vec}:
		\begin{equation}\label{eq::feature_vec}
			\text{feature\_vector} = \begin{bmatrix}
				statistics(degree_{facets})\\
				statistics(areas_{facets})\\
				statistics(centroid_{facets})\\
				statistics(normals_{facets})\\
				statistics(nomals\_with\_relations_{facets})
		\end{bmatrix}
		\end{equation}
		where:
		\begin{equation}
			statistics: property \mapsto \begin{bmatrix}
			\max_{facets}(property)\\
			\min_{facets}(property)\\
			mean_{facets}(property)\\
			median_{facets}(property)
		\end{bmatrix}
		\end{equation}
		\item[(ii).] Altimetric features: using the raster projections and the provided DSM, I computed the difference and used the its histogram as a feature vector. I can also try Bredif's method for DSM roof fitting later on.
		\item[(iii.)] Image features: left for later.
	\end{itemize}

	For now, I have focused on geometric features and altimetic features to complete the whole classification pipeline.The graph kernel methods and ortho image features are left for later. I should also grow my labelled datasets and invistigate other regions by active learning: transforming the pipeline to an active setting.

	\section{Experiments}
~\\
	\subsection{Features visualization}

	I tried visualizing features by reducing their dimensions using PCA. In Figure~\ref{fig::pca_viz}, we can see in snapshots what looks like structures in data.

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\ffigbox
		{
			\ffigbox[\FBwidth]
			{
				\begin{subfloatrow}[3]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/geom_feat_1.eps}}
					}
					{
						\caption{We can see strips like structure of data.}\label{fig::geom_1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/geom_feat_2.eps}}
					}
					{
						\caption{We cannot see much in this direction.}\label{fig::geom_2}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/geom_feat_3.eps}}
					}
					{
						\caption{We can observe some local structures but nothing global.}\label{fig::geom_3}
					}
				\end{subfloatrow}
			}
			{
				\caption*{(i). Visualization of geometric features.}
			}
			\ffigbox[\FBwidth]
			{
				\begin{subfloatrow}[3]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/alti_feat_1.eps}}
					}
					{
						\caption{We can see how the classes are disposed in halo like structures.}\label{fig::alti_1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/alti_feat_2.eps}}
					}
					{
						\caption{This take confirms the fact that `None' errors are in the center followed by `Facet' errors and `Building' erros at last.}\label{fig::alti_2}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/alti_feat_3.eps}}
					}
					{
						\caption{We can see clearly the halo like structures.}\label{fig::alti_3}
					}
				\end{subfloatrow}
			}
			{
				\caption*{(ii). Visualization of altimetric features.}
			}
			\ffigbox[\FBwidth]
			{
				\begin{subfloatrow}[3]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/fused_feat_1.eps}}
					}
					{
						\caption{We keep the same disposition of classes as in altimetric features.}\label{fig::fused_1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/fused_feat_2.eps}}
					}
					{
						\caption{The same halos as in Figure~\ref{fig::pca_viz} -- (ii) --~\ref{fig::alti_3} but more compact.}\label{fig::fused_2}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.31\textwidth]{../images/vizualization/fused_feat_3.eps}}
					}
					{
						\caption{The same forms as in Figure~\ref{fig::pca_viz} -- (ii) --~\ref{fig::alti_2}.}\label{fig::fused_3}
					}
				\end{subfloatrow}
			}
			{
				\caption*{(iii). Visualization fused features.}
			}
		}
		{
			\caption{\label{fig::pca_viz} Visualization of \textit{PCA} reduced features.}
		}
	\end{figure}

	I am trying also to cluster the features in between $9$ --- number of all subclasses --- and $3$ --- number of Coarse classes --- clusters. The idea is to see if features can be interpreted and are well defined or we are overfitting during classification. In Figure~\ref{fig::clust_viz}, we choose 7 clusters. The outliers cause both methods to have clusters with only one element, but otherwise we can see how it can capture coarse structures in data that do not correspond always to defined classes.

	\thisfloatsetup{heightadjust=object}
	\begin{figure}[H]
		\ffigbox{
			\ffigbox[\FBwidth]{
				\begin{subfloatrow}[2]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.48\textwidth]{../images/vizualization/kmeans_7_1.eps}}
					}
					{
						\caption{.}\label{fig::kmeans_1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.48\textwidth]{../images/vizualization/kmeans_7_2.eps}}
					}
					{
						\caption{.}\label{fig::kmeans_2}
					}
				\end{subfloatrow}
			}
			{
				\caption*{(i). Visualization of K-means results.}
			}
			\ffigbox[\FBwidth]
			{
				\begin{subfloatrow}[2]
					\captionsetup{labelformat=brace, justification=raggedright}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.48\textwidth]{../images/vizualization/spectral_clus_7_1.eps}}
					}
					{
						\caption{.}\label{fig::spectral_1}
					}
					\ffigbox[\FBwidth]
					{
						\fbox{\includegraphics[width=.48\textwidth]{../images/vizualization/spectral_clus_7_2.eps}}
					}
					{
						\caption{.}\label{fig::spectral_2}
					}
				\end{subfloatrow}
			}
			{
				\caption*{(ii). Visualization of Spectral clustering results.}
			}
		}
		{
			\caption{\label{fig::clust_viz} Visualization of \textit{PCA} reduced clusters: we specified for both methods $7$ clusters.}
		}
	\end{figure}

	\subsection{Classification results}

	The classification pipeline is subdivided into two phases:

	\begin{itemize}
		\item[(i).] Binary classification: the idea is to use geometric features to predict the unqualified builings which are to be discarded. They cannot be classified and can be determined by the operator. We site in Table~\ref{tab::binary_rf_1000_4} the results of a $10$-fold cross validation using $1000$ $4$ deep Random Forests as a classifier.

		\item[(ii).] Coarse Multi classification: classifies qualified buildings by the error classes: `None', `Building error', `Facet error'. We can observe the results of cross validated \textit{Random Forests} and \textit{SVM} in Figure~\ref{fig::class_viz}. We can also observe how facet relations play a big role in the classification in Figure~\ref{fig::feat_import}.
	\end{itemize}

	\begin{table}[H]
		\caption{\label{tab::binary_rf_1000_4}Binary classification results using a $1000$ $4$ deep Random Forests.}
		\begin{tabular}{|c|c|c|}
			\hline
			Class statistics & \multicolumn{2}{|c|}{[$11.55$\%, $88.45$\%]} \\
			\hline
			\multicolumn{3}{|c|}{Cross validation results}\\
			\hline
			Metric & max & min \\
			 \hline
			train scores & $1.000$ & $0.9911$ \\
			 \hline
			fit time & $1.779$ secs & $1.693$ secs \\
			 \hline
			test scores & $1.000$ & $0.8775$\\
			 \hline
			score time & $0.2507$ secs & $0.2020$ secs\\
			 \hline
		\end{tabular}
	\end{table}

	\begin{figure}[H]
		\ffigbox{
			\ffigbox[\FBwidth]{
				\begin{subfloatrow}[1]
					\captionsetup{labelformat=brace, justification=raggedright}
						\fbox{\includegraphics[width=.75\textwidth]{../images/classification/rf_geom_depth_nbr50}}
				\end{subfloatrow}
			}
			{
				\caption*{(i). Visualization of \textit{Random Forest} results on geometric features.}
			}
			\ffigbox[\FBwidth]{
				\begin{subfloatrow}[1]
					\captionsetup{labelformat=brace, justification=raggedright}
						\fbox{\includegraphics[width=.75\textwidth]{../images/classification/rf_geom_altim_depth_nbr25}}
				\end{subfloatrow}
			}
			{
				\caption*{(ii). Visualization of \textit{Random Forest} results on fused features.}
			}
			\ffigbox[\FBwidth]{
				\begin{subfloatrow}[1]
					\captionsetup{labelformat=brace, justification=raggedright}
						\fbox{\includegraphics[width=.75\textwidth]{../images/classification/svm_C10pgo5_20_gamma_10pgo5_200}}
				\end{subfloatrow}
			}
			{
				\caption*{(iii). Visualization of \textit{SVM} results.}
			}
		}
		{
			\caption{\label{fig::class_viz} Visualization of Cross validated coarse classification scores.}
		}
	\end{figure}

	\begin{figure}[H]
		\ffigbox[\FBwidth]{
			\begin{subfloatrow}[1]
				\captionsetup{labelformat=brace, justification=raggedright}
				\fbox{\includegraphics[width=.75\textwidth]{../images/classification/feat_importance_rf}}
			\end{subfloatrow}
		}
		{
			\caption{\label{fig::feat_import} Pie chart visualizing feature importance.}
		}
	\end{figure}

	The work is still at its begining. I need to classify now on subclasses and try to link the results back to real building in QGIS.

	\section*{Attachments}
	\begin{itemize}
		\item[-] You can checkout the preprocessing code on
		\href{https://github.com/ethiy/proj.city}{Github}.
		\item[-] You can also check the feature extraction and classification code
		\href{https://github.com/ethiy/qualcity}{here}.
	\end{itemize}

	\bibliographystyle{apalike}
	\bibliography{references}

\end{document}
