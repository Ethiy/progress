\documentclass[../main.tex]{subfiles}

\begin{document}
    \section{Motivation}

    Urban model have a wide application range from planning to simulation or visualization. Indeed, $3D$ city models can be used to efficiently plan cell phone tower constructions. It can be also handy in run-off water simulations in order to design flood proof cities and prevent massive damages during natural disasters. In Table~\ref{tab::3d_applications}, we cite some of the main applications of these models.\\

    \begin{table}[H]
        \begin{center}
            \begin{tabular}{c c c}
                \toprule
                Planing & Simulation & Visualization\\
                \midrule
                city planning & fluid dispersion & architecture \\
                emergency planning & wave propagation & cadastre \\
                home decoration & video games & tourism \\
                \bottomrule
            \end{tabular}
            \caption{\label{tab::3d_applications} Some of the main thematic applications of $3D$ urban reconstruction\cite{Scholze2002}.}
        \end{center}
    \end{table}

    In consequence, $3D$ urban reconstruction is a very active research subject. It focuses the efforts many research communities: Computer Vision, Photogrametry \& Remote Sensing and Computer Graphics~\cite{Musialski2012}. Industry is interested also by this domain. In fact, from entertainement companies to defence corporations, any advance in the research would impact greatly on their products.\\

    \begin{figure}[H]
        \begin{center}
            \includestandalone[mode=buildnew, width=\textwidth]{situation}
            \caption{\label{fig::situation} We position ourselves at the junction between the human interaction and the urban model correction phase.}
        \end{center}
    \end{figure}

    In spite of efforts in the research community, urban modelling widely involves human interaction~\cite{Musialski2012}. In fact, even though automatic reconstruction models are seemless, they require human operator to control the quality of the final output. The laborious human correction process actually require a tedious amount of time, which enticies the non-scalability of the overall process. It is then paramount that we procure a qualification method that can easily recognize an error in the $3D$ model and potentially recommend, accordingly, a set of simple actions to the operator. Such a qualification process can also be harnessed in order to qualify whole reconstruction processes on different regions knowing the coveted degree of details.\\

    Building recontruction evaluation is arguably the most strenuous task in urban modelling. A multitude of qualification methods were proposed early in the new millenium. Most of which rely on the presence of reference data that the output models are compared against. The earliest study found~\cite{Henricsson1997} distinguishes three criteria in order to qualify building models: completeness, geometric accuracy and shape dissimilarity. The reference buildings were manually acquired with high accuracy\footnote{$ \vert \sigma_{xyz} \vert \leq 0.01 m$.}. Another generative approach, based on the analysis of reconstruction methods~\cite{Voegtle2003}, determined factors that can affect building models: input data accuracy, data quantization, plane segmentation and planar mesh generalization\footnote{These factors were infered on laser data derived urban reconstruction.}. Those factors led to two quality measurements: positional and height accuracy. Both are computed using some discretization while that first was also obtained based on a aerial approach. The reference data they used were acquired through geodetic measurements with high order of accuracy\footnote{$ \vert \sigma_{xyz} \vert \leq 0.05 m $.}. Accurate building models are also used as reference in~\cite{Zeng2014}. They define a multicriterea evaluation based on three elements: the volume, using the percentage of volume discrepency, the surface, obtained from SPHARM\footnote{what is SPHARM?} expansion, and feature points\footnote{corners and centroids.} by computing their respective positionnal accuracy. In an effort to compare methods by the EuroSDR community~\cite{Kaartinen2005}, reference points were used to analyse the accuracy of the location (single point measurement), length (distance between two points) and roof inclination. These quantities were measured using statistics over squared error --- mean, minimum, maximum, medium and interquartile range ($\frac{1}{4}$ and $\frac{3}{4}$ quartiles). There are other methods that use point clouds as their reference. In fact they are cheaper to get than manually measuring buildings to construct virtual models in their likeness. Reference Laser point clouds were used~\cite{Akca2010} to identify three error classes: systematic, gross and random errors. They proceed first by computing 3D spatial distances between LiDAR points and the corresponding models using LS3D\footnote{what is LS3D}. This first step is useful in order to shed light on reference system dissimilarities. In a second step, the LS3D algorithm is run fully so as to obtain the final geometric transformation --- it is usually a translation --- between the reference and input data. The 3D correspondances are computed using the same algorithm in the third and final step. These measurements are then used to assess the input dataset quality. All these methods can be summurized in a general framework~\cite{Schuster2003} to assess the accuracy of data and its degree of generalization. In this framework, since 3D reference data are not easy to obtain, 2D data are proposed as partial or full substitute.\\

    Reference models are, as pointed out earlier~\cite{Schuster2003}, very expensive to come by and are not an option if one wants to qualify a whole urban scene, a city for instance. Even if we suppose that we can generalize the quality by acquiring reference models on representative buildings, one has to study the input dataset and extract those samples that yield enough generalization power to predict the quality of the whole scene. This being said, the qualification process can be undertaken under a different perspective. One can predict the quality by looking into the intrensic building model characteristics: we would not need to produce complicated reference models to assess the quality of a reconstruction. In fact, one can predict the quality of models using internal quality measures~\cite{OudeElberink2010}. We start off by qualifying the input data. The input accuracy impacts directly the output. The absence of data is also an issue to be quantified. One can also look into geometrical features: planar segments, roof edges, corner points and height jumps. The proposed methodology uses orthogonal differences between laser points and the corresponding planes. We can use then the residuals to assess the model by stating the observed error. This method is to be used while producing the models: we can describe it as an online method. It has then to be presented to operators for interpretation. One other way is to automatically extract errors from the computed measurements. The problem can be formulated then as a suprevised classification problem~\cite{Boudet2006}. The classes correspond to the traffic light paradigm: correct, acceptable, generalized and false. These errors correspond to the degree of confidence in the input data correctness. The features, which the classifier learns on, are extracted from the model, the overlapping aerial images and Digital Surface Models. A similar approach using the supervized classification~\cite{michelin2013quality}, the error taxonomy is based on semantic problems that can affect building models. The method was studied on LoD 2 data. The taxonomy identifies then all errors corresponding to all LoD up to the data level (a.k.a 2). The features are extracted from 3D, image and DSM based, segments Sky Viewshed angle and the NDVI mask. Usually, topological errors are easily detected than the inprecision related ones.\\

    \begin{sidewaystable}[H]
        \begin{center}
            \begin{tabular}{c x{6cm} x{8cm}}
                \toprule
                Method & Reference data & Studied errors \\
                \midrule
                \cite{Henricsson1997} & Manually measured. Accuracy: $ \vert \sigma_{xyz} \vert \leq 0.01 m$ & Completeness, geometric accuracy and shape dissimilarity \\
                \midrule
                \cite{Voegtle2003} & Manually measured. Accuracy: $ \vert \sigma_{xyz} \vert \leq 0.05 m$ & Positional and height accuracy \\
                \midrule
                \cite{Zeng2014} & Manually measured. Accuracy: depends on LiDAR and image data & Volume, surface and point imprecision \\
                \midrule
                \cite{Kaartinen2005} & Manually measured. Accuracy: $ \vert \sigma_{xy} \vert \leq 0.083 m$ and $ \vert \sigma_{z} \vert \leq 0.035 m$ & Location, length and roof inclination accuracy \\
                \midrule
                \cite{Akca2010} & LiDAR points. Accuracy: $25 pts/m^2$ density & Systematic, gross and random errors\\
                \midrule
                \cite{Schuster2003} & 3D data or 2D data & Building detection and reconstruction \\
                \midrule
                \cite{OudeElberink2010} & Laser points used for the reconstruction & Data dependent \\
                \midrule
                \cite{Boudet2006} & The learned model from the annotated data & Error classes: false, generalized, acceptable and correct \\
                \midrule
                \cite{michelin2013quality} & The learned model from the annotated data & Error classes: erronous outline, unexisting building, missing inner court, inaccurate footprint, under-segmentation, over-segmentation, inaccurate roof, z translation and vegetation occlusion \\
                \bottomrule
            \end{tabular}
        \end{center}
        \caption{\label{tab::bib_sum} Summary of quality evaluation methods found in litterature.}
    \end{sidewaystable}

\end{document}
